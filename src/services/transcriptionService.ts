import { AssemblyAI } from 'assemblyai'

export interface TranscriptionWord {
  text: string
  start: number
  end: number
  confidence: number
  highlight?: boolean
  speaker?: string
}

export interface TranscriptionResult {
  words: TranscriptionWord[]
  text: string
  confidence: number
  language?: string
  duration?: number
  speakers?: string[]
}

export interface WhisperResponse {
  text: string
  segments: WhisperSegment[]
  language: string
}

export interface WhisperSegment {
  id: number
  start: number
  end: number
  text: string
  words?: WhisperWord[]
}

export interface WhisperWord {
  word: string
  start: number
  end: number
}

class TranscriptionService {
  private assemblyAI: AssemblyAI | null = null
  private apiKey: string = ''
  private openaiApiKey: string = ''

  setApiKey(apiKey: string) {
    this.apiKey = apiKey
    this.assemblyAI = new AssemblyAI({
      apiKey: apiKey
    })
  }

  setOpenAIApiKey(apiKey: string) {
    this.openaiApiKey = apiKey
  }

  private isSecureContext(): boolean {
    return window.isSecureContext || location.protocol === 'https:' || location.hostname === 'localhost'
  }

  private async extractAudioFromVideo(videoFile: File): Promise<File> {
    return new Promise((resolve, reject) => {
      const video = document.createElement('video')
      const canvas = document.createElement('canvas')
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
      
      video.onloadedmetadata = () => {
        const duration = video.duration
        video.currentTime = 0
        
        resolve(videoFile)
      }
      
      video.onerror = () => reject(new Error('Erro ao processar v√≠deo'))
      video.src = URL.createObjectURL(videoFile)
    })
  }

  // ‚ûï NOVO: Transcri√ß√£o OpenAI Whisper (MELHOR QUALIDADE/PRE√áO)
  async transcribeWithWhisper(
    videoFile: File, 
    onProgress: (status: string) => void
  ): Promise<TranscriptionResult> {
    if (!this.openaiApiKey) {
      throw new Error('üîë Configure sua API Key do OpenAI primeiro!\n\nüìç Onde obter: https://platform.openai.com/api-keys\nüí∞ Custo: $0.006/minuto\nüéØ Melhor qualidade de transcri√ß√£o');
    }

    try {
      onProgress('üé§ Preparando √°udio para OpenAI Whisper...')
      
      if (videoFile.size > 25 * 1024 * 1024) {
        throw new Error('üìÅ Arquivo muito grande para Whisper (m√°x 25MB).\n\nüí° Alternativa: Use AssemblyAI que n√£o tem limite de tamanho.\nüåê https://www.assemblyai.com/dashboard/signup');
      }

      onProgress('üì§ Enviando para OpenAI Whisper...')

      const formData = new FormData()
      formData.append('file', videoFile)
      formData.append('model', 'whisper-1')
      formData.append('language', 'pt') // Portugu√™s por padr√£o
      formData.append('response_format', 'verbose_json') // Para ter timestamps
      formData.append('timestamp_granularities[]', 'word') // Timestamps por palavra

      // Chamada para OpenAI Whisper API
      const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.openaiApiKey}`,
        },
        body: formData
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        let errorMessage = `OpenAI API Error: ${response.status}`
        
        if (response.status === 401) {
          errorMessage = 'üîë API Key inv√°lida!\n\nüìç Verifique se copiou corretamente de:\nhttps://platform.openai.com/api-keys\n\nüí° A key deve come√ßar com "sk-"'
        } else if (response.status === 429) {
          errorMessage = '‚è≥ Limite de rate excedido!\n\nüí° Aguarde alguns minutos ou:\nüîÑ Use AssemblyAI como alternativa'
        } else if (errorData.error?.message) {
          errorMessage += ` - ${errorData.error.message}`
        }
        
        throw new Error(errorMessage)
      }

      onProgress('üß† Processando resposta do Whisper...')

      const result: WhisperResponse = await response.json()

      onProgress('‚úÖ Transcri√ß√£o Whisper conclu√≠da!')

      // Converter para nosso formato padr√£o
      const words: TranscriptionWord[] = []

      // Processar segments e words
      if (result.segments) {
        result.segments.forEach((segment, segIndex) => {
          if (segment.words && segment.words.length > 0) {
            // Se tem words com timestamps precisos
            segment.words.forEach(word => {
              words.push({
                text: word.word.trim(),
                start: word.start,
                end: word.end,
                confidence: 0.95, // Whisper tem alta confian√ßa
                highlight: word.word.length > 6, // Highlight palavras longas
                speaker: `Speaker ${segIndex % 2 + 1}` // Speakers b√°sicos
              })
            })
          } else {
            // Fallback: dividir texto por palavras e estimar timestamps
            const segmentWords = segment.text.trim().split(/\s+/)
            const wordDuration = (segment.end - segment.start) / segmentWords.length

            segmentWords.forEach((word, index) => {
              if (word.trim()) {
                const wordStart = segment.start + (index * wordDuration)
                words.push({
                  text: word.trim(),
                  start: wordStart,
                  end: wordStart + wordDuration,
                  confidence: 0.95,
                  highlight: word.length > 6,
                  speaker: `Speaker ${segIndex % 2 + 1}`
                })
              }
            })
          }
        })
      }

      // Calcular estat√≠sticas
      const duration = words.length > 0 ? Math.max(...words.map(w => w.end)) : 0
      const speakers = [...new Set(words.map(w => w.speaker).filter((s): s is string => Boolean(s)))]

      return {
        words,
        text: result.text || '',
        confidence: 0.95, // Whisper tem alta qualidade
        language: result.language || 'pt',
        duration,
        speakers
      }

    } catch (error) {
      console.error('Erro OpenAI Whisper:', error)
      throw error
    }
  }

  // M√©todo de upload removido - usando upload direto do arquivo

  // ü§ñ EXISTING: Transcri√ß√£o AssemblyAI (MELHOR PARA ARQUIVOS GRANDES)
  async transcribeWithAssemblyAI(
    videoFile: File, 
    onProgress: (status: string) => void
  ): Promise<TranscriptionResult> {
    if (!this.assemblyAI) {
      throw new Error('üîë Configure sua API Key da AssemblyAI primeiro!\n\nüìç Onde obter: https://www.assemblyai.com/dashboard/signup\nüéÅ 5 horas gr√°tis para testar\nüí∞ Custo: $0.37/hora');
    }

    try {
      onProgress('üì§ Enviando √°udio para AssemblyAI...')

      // Primeiro, fazer upload do arquivo
      const uploadFormData = new FormData()
      uploadFormData.append('file', videoFile)

      const uploadResponse = await fetch('https://api.assemblyai.com/v2/upload', {
        method: 'POST',
        headers: {
          'Authorization': this.apiKey,
        },
        body: uploadFormData
      })

      if (!uploadResponse.ok) {
        const errorData = await uploadResponse.json().catch(() => ({}))
        let errorMessage = `AssemblyAI Upload Error: ${uploadResponse.status}`
        
        if (uploadResponse.status === 401) {
          errorMessage = 'üîë API Key da AssemblyAI inv√°lida!\n\nüìç Verifique se copiou corretamente de:\nhttps://www.assemblyai.com/dashboard\n\nüí° Certifique-se de estar logado'
        } else if (uploadResponse.status === 429) {
          errorMessage = '‚è≥ Limite de rate excedido!\n\nüí° Aguarde alguns minutos ou:\nüîÑ Use OpenAI Whisper como alternativa'
        } else if (errorData.error) {
          errorMessage += ` - ${errorData.error}`
        }
        
        throw new Error(errorMessage)
      }

      onProgress('üß† Processando com IA...')
      
      // Configura√ß√£o oficial AssemblyAI
      const transcript = await this.assemblyAI.transcripts.create({
        audio_url: await this.assemblyAI.files.upload(videoFile),
        language_detection: true,
        speaker_labels: true,
        auto_highlights: true,
        word_boost: ['viral', 'incr√≠vel', 'nunca', 'melhor', 'top', 'insano', 'perfeito'],
        punctuate: true,
        format_text: true,
        dual_channel: false,
        webhook_url: undefined, // N√£o usar webhook para simplicidade
        boost_param: 'high', // Melhor qualidade
        redact_pii: false,
        redact_pii_audio: false,
        redact_pii_policies: undefined,
        redact_pii_sub: undefined
      })

      onProgress('‚è≥ Aguardando processamento...')
      
      // Polling oficial (seguindo docs)
      let result = transcript
      let attempts = 0
      const maxAttempts = 150 // 5 minutos m√°ximo
      
      while ((result.status === 'processing' || result.status === 'queued') && attempts < maxAttempts) {
        await new Promise(resolve => setTimeout(resolve, 2000))
        result = await this.assemblyAI.transcripts.get(transcript.id)
        onProgress(`üîÑ Processando... (${result.status}) - ${attempts + 1}/${maxAttempts}`)
        attempts++
      }

      if (result.status === 'error') {
        throw new Error(`Erro AssemblyAI: ${result.error}`)
      }

      if (result.status !== 'completed') {
        throw new Error('Timeout no processamento AssemblyAI')
      }

      onProgress('‚úÖ Transcri√ß√£o AssemblyAI conclu√≠da!')

      // Converter para nosso formato
      const words: TranscriptionWord[] = result.words?.map(word => ({
        text: word.text,
        start: word.start / 1000, // AssemblyAI usa millisegundos
        end: word.end / 1000,
        confidence: word.confidence,
        highlight: word.confidence > 0.95 // Auto-highlight alta confian√ßa
      })) || []

      return {
        words,
        text: result.text || '',
        confidence: result.confidence || 0
      }

    } catch (error) {
      console.error('Erro AssemblyAI:', error)
      throw error
    }
  }

  // Web Speech API simplificada (sem problemas de CSP)
  async transcribeWithWebSpeech(
    _videoFile: File, // N√£o usado nesta implementa√ß√£o
    onProgress: (status: string) => void
  ): Promise<TranscriptionResult> {
    // Verificar contexto seguro (requisito W3C)
    if (!this.isSecureContext()) {
      throw new Error('Web Speech API requer HTTPS ou localhost')
    }

    // Verificar suporte (especifica√ß√£o W3C)
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      throw new Error('Web Speech API n√£o suportada neste navegador. Use Chrome ou Edge.')
    }

    return new Promise((resolve, reject) => {
      onProgress('üé§ Iniciando Web Speech API...')

      // Configura√ß√£o oficial W3C
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
      const recognition = new SpeechRecognition()
      
      // Configura√ß√µes seguindo especifica√ß√£o W3C
      recognition.continuous = true
      recognition.interimResults = true
      recognition.lang = 'pt-BR'
      recognition.maxAlternatives = 3

      let finalTranscript = ''
      let words: TranscriptionWord[] = []
      let startTime = 0

      recognition.onstart = () => {
        onProgress('üé§ Web Speech ativo - fale no microfone...')
        startTime = Date.now()
      }

      recognition.onresult = (event: any) => {
        let interimTranscript = ''
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i]
          const transcript = result[0].transcript
          const confidence = result[0].confidence || 0.8
          
          if (result.isFinal) {
            finalTranscript += transcript + ' '
            
            // Calcular timestamps baseados no tempo decorrido
            const currentTime = (Date.now() - startTime) / 1000
            const wordsArray = transcript.trim().split(' ')
            const wordDuration = 0.6 // Dura√ß√£o m√©dia por palavra
            
            wordsArray.forEach((word: string, index: number) => {
              if (word.trim()) {
                const wordStart = Math.max(0, currentTime - (wordsArray.length * wordDuration) + (index * wordDuration))
                words.push({
                  text: word.trim(),
                  start: wordStart,
                  end: wordStart + wordDuration,
                  confidence: confidence,
                  highlight: confidence > 0.9 || word.length > 6 // Highlight palavras longas ou alta confian√ßa
                })
              }
            })
          } else {
            interimTranscript += transcript
          }
        }
        
        const displayText = interimTranscript || finalTranscript.slice(-50)
        onProgress(`üé§ Transcrevendo: "${displayText}..."`)
      }

      recognition.onerror = (event: any) => {
        let errorMessage = 'Erro no reconhecimento de voz'
        
        // Mensagens de erro espec√≠ficas (seguindo spec W3C)
        switch (event.error) {
          case 'not-allowed':
            errorMessage = 'üîá Permiss√£o negada para microfone!\n\nüí° Para usar Web Speech API:\n‚Ä¢ Permita acesso ao microfone\n‚Ä¢ Certifique-se de que h√° um microfone conectado\n\nüéØ Alternativa: Use OpenAI Whisper (melhor qualidade)'
            break
          case 'no-speech':
            errorMessage = 'üé§ Nenhuma fala detectada!\n\nüí° Certifique-se de:\n‚Ä¢ Estar falando no microfone\n‚Ä¢ Microfone n√£o est√° mutado\n‚Ä¢ Volume adequado\n\nüéØ Alternativa: Use OpenAI Whisper ou AssemblyAI para v√≠deos'
            break
          case 'audio-capture':
            errorMessage = 'üéß Erro na captura de √°udio!\n\nüí° Poss√≠veis solu√ß√µes:\n‚Ä¢ Reconecte o microfone\n‚Ä¢ Permita acesso ao √°udio\n‚Ä¢ Teste outro navegador\n\nüéØ Alternativa: Use APIs pagas (Whisper/AssemblyAI)'
            break
          case 'network':
            errorMessage = 'üåê Erro de rede!\n\nüí° Web Speech precisa de conex√£o.\n\nüéØ Alternativa: OpenAI Whisper funciona offline ap√≥s upload'
            break
          case 'service-not-allowed':
            errorMessage = 'Servi√ßo n√£o permitido'
            break
          default:
            errorMessage = `Erro Web Speech: ${event.error}`
        }
        
        reject(new Error(errorMessage))
      }

      recognition.onend = () => {
        onProgress('‚úÖ Web Speech API conclu√≠da!')
        resolve({
          words,
          text: finalTranscript.trim(),
          confidence: 0.8
        })
      }

      // Iniciar reconhecimento direto do microfone
      recognition.start()
      
      // Auto-parar ap√≥s 30 segundos
      setTimeout(() => {
        recognition.stop()
      }, 30000)
    })
  }

  // ‚ûï M√âTODO PRINCIPAL com suporte a 3 servi√ßos
  async transcribe(
    videoFile: File,
    onProgress: (status: string) => void,
    provider: 'whisper' | 'assemblyai' | 'webspeech' = 'whisper', // ‚ûï NOVO: Whisper como padr√£o
    useWebSpeechFallback: boolean = true
  ): Promise<TranscriptionResult> {
    // Tentativa com provedor escolhido
    try {
      switch (provider) {
        case 'whisper':
          if (!this.openaiApiKey) {
            throw new Error('Configure OpenAI API Key para usar Whisper')
          }
          onProgress('üéØ Iniciando OpenAI Whisper (Melhor qualidade)...')
          return await this.transcribeWithWhisper(videoFile, onProgress)
          
        case 'assemblyai':
          if (!this.apiKey || !this.assemblyAI) {
            throw new Error('Configure AssemblyAI API Key primeiro')
          }
          onProgress('ü§ñ Iniciando AssemblyAI (R√°pido e confi√°vel)...')
          return await this.transcribeWithAssemblyAI(videoFile, onProgress)
          
        case 'webspeech':
          onProgress('üé§ Iniciando Web Speech API (Gr√°tis, microfone)...')
          return await this.transcribeWithWebSpeech(videoFile, onProgress)
          
        default:
          throw new Error(`Provedor n√£o suportado: ${provider}`)
      }
    } catch (error) {
      console.error(`Erro com ${provider}:`, error)
      
      // Fallback hier√°rquico baseado no provedor original
      if (useWebSpeechFallback && provider !== 'webspeech') {
        onProgress(`‚ùå Erro com ${provider}. Tentando Web Speech...`)
        try {
          return await this.transcribeWithWebSpeech(videoFile, onProgress)
        } catch (fallbackError) {
          console.error('Erro no fallback Web Speech:', fallbackError)
        }
      }
      
      // Se chegou aqui, todos os m√©todos falharam
      throw error
    }
  }

  // ‚ûï M√âTODO para verificar disponibilidade dos provedores
  getAvailableProviders(): { id: string, name: string, description: string, available: boolean, cost: string }[] {
    return [
      {
        id: 'whisper',
        name: 'üéØ OpenAI Whisper',
        description: 'Melhor qualidade, m√∫ltiplos idiomas, timestamps precisos',
        available: !!this.openaiApiKey,
        cost: '$0.006/min'
      },
      {
        id: 'assemblyai',
        name: 'ü§ñ AssemblyAI',
        description: 'R√°pido, confi√°vel, boa para podcasts longos',
        available: !!this.apiKey && !!this.assemblyAI,
        cost: '$0.37/hr'
      },
      {
        id: 'webspeech',
        name: 'üé§ Web Speech',
        description: 'Gr√°tis, funciona s√≥ com microfone (n√£o com arquivo)',
        available: this.isSecureContext() && (('webkitSpeechRecognition' in window) || ('SpeechRecognition' in window)),
        cost: 'Gr√°tis'
      }
    ]
  }

  // ‚ûï M√âTODO para configurar todas as API keys de uma vez
  configureAllKeys(keys: { openai?: string, assemblyai?: string }) {
    if (keys.openai) {
      this.setOpenAIApiKey(keys.openai)
    }
    if (keys.assemblyai) {
      this.setApiKey(keys.assemblyai)
    }
  }
}

export const transcriptionService = new TranscriptionService() 