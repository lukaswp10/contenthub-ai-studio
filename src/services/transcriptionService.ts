import { AssemblyAI } from 'assemblyai'
import { transcriptionCache, type CachedTranscription } from './transcription/cache.service'
import { configService } from './security/config.service'
import { intelligentFallback, type FallbackResult } from './fallback'

export interface TranscriptionWord {
  text: string
  start: number
  end: number
  confidence: number
  highlight?: boolean
  speaker?: string
}

export interface TranscriptionResult {
  words: TranscriptionWord[]
  text: string
  confidence: number
  language?: string
  duration?: number
  speakers?: string[]
  continuousCaptions: ContinuousCaption[]
  segments: WhisperSegment[]
}

export interface WhisperResponse {
  text: string
  segments: WhisperSegment[]
  language: string
}

export interface WhisperSegment {
  id: number
  start: number
  end: number
  text: string
  words?: WhisperWord[]
}

export interface WhisperWord {
  word: string
  start: number
  end: number
}

class TranscriptionService {
  private assemblyAI: AssemblyAI | null = null
  private apiKey: string = ''
  private openaiApiKey: string = ''

  setApiKey(apiKey: string) {
    this.apiKey = apiKey
    this.assemblyAI = new AssemblyAI({
      apiKey: apiKey
    })
  }

  setOpenAIApiKey(apiKey: string) {
    this.openaiApiKey = apiKey
  }

  private isSecureContext(): boolean {
    return window.isSecureContext || location.protocol === 'https:' || location.hostname === 'localhost'
  }

  private async extractAudioFromVideo(videoFile: File): Promise<File> {
    return new Promise((resolve, reject) => {
      const video = document.createElement('video')
      const canvas = document.createElement('canvas')
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
      
      video.onloadedmetadata = () => {
        const duration = video.duration
        video.currentTime = 0
        
        resolve(videoFile)
      }
      
      video.onerror = () => reject(new Error('Erro ao processar v√≠deo'))
      video.src = URL.createObjectURL(videoFile)
    })
  }

  // ‚ûï NOVO: Transcri√ß√£o OpenAI Whisper (MELHOR QUALIDADE/PRE√áO)
  async transcribeWithWhisper(
    videoFile: File, 
    onProgress: (status: string) => void
  ): Promise<TranscriptionResult> {
    // üîê OBTER API KEY SEGURA
    const openaiConfig = configService.getActiveApiKey('openai')
    if (!openaiConfig) {
      throw new Error('üîë Configure sua API Key do OpenAI primeiro!\n\nüìç Onde obter: https://platform.openai.com/api-keys\nüí∞ Custo: $0.006/minuto\nüéØ Melhor qualidade de transcri√ß√£o\n\n‚ö° Use o Gerenciador de API Keys para configurar');
    }
    
    const apiKey = openaiConfig.key

    try {
      console.log('üöÄ WHISPER: Iniciando transcri√ß√£o')
      console.log('üìÅ WHISPER: Arquivo:', videoFile.name, videoFile.size, 'bytes')
      console.log('üîë WHISPER: API Key configurada:', apiKey.substring(0, 10) + '...')
      
      onProgress('üé§ Preparando √°udio para OpenAI Whisper...')
      
      if (videoFile.size > 25 * 1024 * 1024) {
        throw new Error('üìÅ Arquivo muito grande para Whisper (m√°x 25MB).\n\nüí° Alternativa: Use AssemblyAI que n√£o tem limite de tamanho.\nüåê https://www.assemblyai.com/dashboard/signup');
      }

      onProgress('üì§ Enviando para OpenAI Whisper...')

      const formData = new FormData()
      formData.append('file', videoFile)
      formData.append('model', 'whisper-1')
      formData.append('language', 'pt') // Portugu√™s por padr√£o
      formData.append('response_format', 'verbose_json') // Para ter timestamps
      formData.append('timestamp_granularities[]', 'word') // Timestamps por palavra

      console.log('üì§ WHISPER: FormData preparado')
      console.log('üìã WHISPER: Par√¢metros:', {
        model: 'whisper-1',
        language: 'pt',
        response_format: 'verbose_json',
        timestamp_granularities: 'word'
      })

      // Chamada para OpenAI Whisper API
      const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
        },
        body: formData
      })

      console.log('üì° WHISPER: Resposta recebida')
      console.log('üìä WHISPER: Status:', response.status)
      console.log('üìã WHISPER: Headers:', Object.fromEntries(response.headers.entries()))

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        console.error('‚ùå WHISPER: Erro na API:', errorData)
        
        let errorMessage = `OpenAI API Error: ${response.status}`
        
        if (response.status === 401) {
          errorMessage = 'üîë API Key inv√°lida!\n\nüìç Verifique se copiou corretamente de:\nhttps://platform.openai.com/api-keys\n\nüí° A key deve come√ßar com "sk-"'
        } else if (response.status === 429) {
          errorMessage = '‚è≥ Limite de rate excedido!\n\nüí° Aguarde alguns minutos ou:\nüîÑ Use AssemblyAI como alternativa'
        } else if (errorData.error?.message) {
          errorMessage += ` - ${errorData.error.message}`
        }
        
        throw new Error(errorMessage)
      }

      onProgress('üß† Processando resposta do Whisper...')

      const result: WhisperResponse = await response.json()
      
      console.log('üéâ WHISPER: Dados recebidos!')
      console.log('üìÑ WHISPER: Texto completo:', result.text)
      console.log('üî§ WHISPER: Idioma detectado:', result.language)
      console.log('üìä WHISPER: Segments:', result.segments?.length || 0)
      console.log('üîç WHISPER: Primeiro segment:', result.segments?.[0])

      onProgress('‚úÖ Transcri√ß√£o Whisper conclu√≠da!')

      // Converter para nosso formato padr√£o
      const words: TranscriptionWord[] = []

      console.log('üîÑ WHISPER: Processando segments...')

      // Processar segments e words
      if (result.segments) {
        result.segments.forEach((segment, segIndex) => {
          console.log(`üìù WHISPER: Segment ${segIndex}:`, segment)
          
          if (segment.words && segment.words.length > 0) {
            console.log(`üìù WHISPER: Segment ${segIndex} tem ${segment.words.length} palavras com timestamps`)
            
            // Se tem words com timestamps precisos
            segment.words.forEach((word, wordIndex) => {
              const processedWord = {
                text: word.word.trim(),
                start: word.start,
                end: word.end,
                confidence: 0.95, // Whisper tem alta confian√ßa
                highlight: word.word.length > 6, // Highlight palavras longas
                speaker: `Speaker ${segIndex % 2 + 1}` // Speakers b√°sicos
              }
              
              words.push(processedWord)
              console.log(`üî§ WHISPER: Palavra ${wordIndex}:`, processedWord)
            })
          }
          
          // ‚úÖ SEMPRE executar fallback se n√£o h√° words suficientes
          if (!segment.words || segment.words.length === 0) {
            console.log(`üìù WHISPER: Segment ${segIndex} sem words - usando fallback`)
            
            // Fallback: dividir texto por palavras e estimar timestamps
            const segmentWords = segment.text.trim().split(/\s+/)
            const wordDuration = (segment.end - segment.start) / segmentWords.length

            segmentWords.forEach((word, index) => {
              if (word.trim()) {
                const wordStart = segment.start + (index * wordDuration)
                const processedWord = {
                  text: word.trim(),
                  start: wordStart,
                  end: wordStart + wordDuration,
                  confidence: 0.95,
                  highlight: word.length > 6,
                  speaker: `Speaker ${segIndex % 2 + 1}`
                }
                
                words.push(processedWord)
                console.log(`üî§ WHISPER: Palavra fallback ${index}:`, processedWord)
              }
            })
          }
        })
      }

      // Calcular estat√≠sticas
      const duration = words.length > 0 ? Math.max(...words.map(w => w.end)) : 0
      const speakers = [...new Set(words.map(w => w.speaker).filter((s): s is string => Boolean(s)))]

      const finalResult = {
        words,
        text: result.text || '',
        confidence: 0.95, // Whisper tem alta qualidade
        language: result.language || 'pt',
        duration,
        speakers,
        continuousCaptions: createContinuousCaptions(words),
        segments: result.segments || []
      }

      console.log('‚úÖ WHISPER: Resultado final processado!')
      console.log('üìä WHISPER: Total de palavras:', words.length)
      console.log('‚è±Ô∏è WHISPER: Dura√ß√£o:', duration)
      console.log('üë• WHISPER: Speakers:', speakers)
      console.log('üéØ WHISPER: Resultado completo:', finalResult)

      return finalResult

    } catch (error) {
      console.error('‚ùå WHISPER: Erro completo:', error)
      console.error('üîç WHISPER: Stack trace:', error instanceof Error ? error.stack : 'Sem stack')
      throw error
    }
  }

  // M√©todo de upload removido - usando upload direto do arquivo

  // ü§ñ EXISTING: Transcri√ß√£o AssemblyAI (MELHOR PARA ARQUIVOS GRANDES)
  async transcribeWithAssemblyAI(
    videoFile: File, 
    onProgress: (status: string) => void
  ): Promise<TranscriptionResult> {
    // üîê OBTER API KEY SEGURA
    const assemblyConfig = configService.getActiveApiKey('assemblyai')
    if (!assemblyConfig) {
      throw new Error('üîë Configure sua API Key da AssemblyAI primeiro!\n\nüìç Onde obter: https://www.assemblyai.com/dashboard/signup\nüéÅ 5 horas gr√°tis para testar\nüí∞ Custo: $0.37/hora\n\n‚ö° Use o Gerenciador de API Keys para configurar');
    }
    
    const assemblyAI = new AssemblyAI({ apiKey: assemblyConfig.key })
    const apiKey = assemblyConfig.key

    try {
      onProgress('üì§ Enviando √°udio para AssemblyAI...')

      // Primeiro, fazer upload do arquivo
      const uploadFormData = new FormData()
      uploadFormData.append('file', videoFile)

      const uploadResponse = await fetch('https://api.assemblyai.com/v2/upload', {
        method: 'POST',
        headers: {
          'Authorization': apiKey,
        },
        body: uploadFormData
      })

      if (!uploadResponse.ok) {
        const errorData = await uploadResponse.json().catch(() => ({}))
        let errorMessage = `AssemblyAI Upload Error: ${uploadResponse.status}`
        
        if (uploadResponse.status === 401) {
          errorMessage = 'üîë API Key da AssemblyAI inv√°lida!\n\nüìç Verifique se copiou corretamente de:\nhttps://www.assemblyai.com/dashboard\n\nüí° Certifique-se de estar logado'
        } else if (uploadResponse.status === 429) {
          errorMessage = '‚è≥ Limite de rate excedido!\n\nüí° Aguarde alguns minutos ou:\nüîÑ Use OpenAI Whisper como alternativa'
        } else if (errorData.error) {
          errorMessage += ` - ${errorData.error}`
        }
        
        throw new Error(errorMessage)
      }

      onProgress('üß† Processando com IA...')
      
      // Configura√ß√£o oficial AssemblyAI
      const transcript = await assemblyAI.transcripts.create({
        audio_url: await assemblyAI.files.upload(videoFile),
        language_detection: true,
        speaker_labels: true,
        auto_highlights: true,
        word_boost: ['viral', 'incr√≠vel', 'nunca', 'melhor', 'top', 'insano', 'perfeito'],
        punctuate: true,
        format_text: true,
        dual_channel: false,
        webhook_url: undefined, // N√£o usar webhook para simplicidade
        boost_param: 'high', // Melhor qualidade
        redact_pii: false,
        redact_pii_audio: false,
        redact_pii_policies: undefined,
        redact_pii_sub: undefined
      })

      onProgress('‚è≥ Aguardando processamento...')
      
      // Polling oficial (seguindo docs)
      let result = transcript
      let attempts = 0
      const maxAttempts = 150 // 5 minutos m√°ximo
      
      while ((result.status === 'processing' || result.status === 'queued') && attempts < maxAttempts) {
        await new Promise(resolve => setTimeout(resolve, 2000))
        result = await assemblyAI.transcripts.get(transcript.id)
        onProgress(`üîÑ Processando... (${result.status}) - ${attempts + 1}/${maxAttempts}`)
        attempts++
      }

      if (result.status === 'error') {
        throw new Error(`Erro AssemblyAI: ${result.error}`)
      }

      if (result.status !== 'completed') {
        throw new Error('Timeout no processamento AssemblyAI')
      }

      onProgress('‚úÖ Transcri√ß√£o AssemblyAI conclu√≠da!')

      // Converter para nosso formato
      const words: TranscriptionWord[] = result.words?.map(word => ({
        text: word.text,
        start: word.start / 1000, // AssemblyAI usa millisegundos
        end: word.end / 1000,
        confidence: word.confidence,
        highlight: word.confidence > 0.95 // Auto-highlight alta confian√ßa
      })) || []

      return {
        words,
        text: result.text || '',
        confidence: result.confidence || 0,
        language: 'pt-BR',
        duration: words.length > 0 ? Math.max(...words.map(w => w.end)) : 0,
        speakers: [...new Set(words.map(w => w.speaker).filter((s): s is string => Boolean(s)))],
        continuousCaptions: createContinuousCaptions(words),
        segments: []
      }

    } catch (error) {
      console.error('Erro AssemblyAI:', error)
      throw error
    }
  }

  // Web Speech API simplificada (sem problemas de CSP)
  async transcribeWithWebSpeech(
    _videoFile: File, // N√£o usado nesta implementa√ß√£o
    onProgress: (status: string) => void
  ): Promise<TranscriptionResult> {
    // Verificar contexto seguro (requisito W3C)
    if (!this.isSecureContext()) {
      throw new Error('Web Speech API requer HTTPS ou localhost')
    }

    // Verificar suporte (especifica√ß√£o W3C)
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      throw new Error('Web Speech API n√£o suportada neste navegador. Use Chrome ou Edge.')
    }

    return new Promise((resolve, reject) => {
      onProgress('üé§ Iniciando Web Speech API...')

      // Configura√ß√£o oficial W3C
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
      const recognition = new SpeechRecognition()
      
      // Configura√ß√µes seguindo especifica√ß√£o W3C
      recognition.continuous = true
      recognition.interimResults = true
      recognition.lang = 'pt-BR'
      recognition.maxAlternatives = 3

      let finalTranscript = ''
      let words: TranscriptionWord[] = []
      let startTime = 0

      recognition.onstart = () => {
        onProgress('üé§ Web Speech ativo - fale no microfone...')
        startTime = Date.now()
      }

      recognition.onresult = (event: any) => {
        let interimTranscript = ''
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i]
          const transcript = result[0].transcript
          const confidence = result[0].confidence || 0.8
          
          if (result.isFinal) {
            finalTranscript += transcript + ' '
            
            // Calcular timestamps baseados no tempo decorrido
            const currentTime = (Date.now() - startTime) / 1000
            const wordsArray = transcript.trim().split(' ')
            const wordDuration = 0.6 // Dura√ß√£o m√©dia por palavra
            
            wordsArray.forEach((word: string, index: number) => {
              if (word.trim()) {
                const wordStart = Math.max(0, currentTime - (wordsArray.length * wordDuration) + (index * wordDuration))
                words.push({
                  text: word.trim(),
                  start: wordStart,
                  end: wordStart + wordDuration,
                  confidence: confidence,
                  highlight: confidence > 0.9 || word.length > 6 // Highlight palavras longas ou alta confian√ßa
                })
              }
            })
          } else {
            interimTranscript += transcript
          }
        }
        
        const displayText = interimTranscript || finalTranscript.slice(-50)
        onProgress(`üé§ Transcrevendo: "${displayText}..."`)
      }

      recognition.onerror = (event: any) => {
        let errorMessage = 'Erro no reconhecimento de voz'
        
        // Mensagens de erro espec√≠ficas (seguindo spec W3C)
        switch (event.error) {
          case 'not-allowed':
            errorMessage = 'üîá Permiss√£o negada para microfone!\n\nüí° Para usar Web Speech API:\n‚Ä¢ Permita acesso ao microfone\n‚Ä¢ Certifique-se de que h√° um microfone conectado\n\nüéØ Alternativa: Use OpenAI Whisper (melhor qualidade)'
            break
          case 'no-speech':
            errorMessage = 'üé§ Nenhuma fala detectada!\n\nüí° Certifique-se de:\n‚Ä¢ Estar falando no microfone\n‚Ä¢ Microfone n√£o est√° mutado\n‚Ä¢ Volume adequado\n\nüéØ Alternativa: Use OpenAI Whisper ou AssemblyAI para v√≠deos'
            break
          case 'audio-capture':
            errorMessage = 'üéß Erro na captura de √°udio!\n\nüí° Poss√≠veis solu√ß√µes:\n‚Ä¢ Reconecte o microfone\n‚Ä¢ Permita acesso ao √°udio\n‚Ä¢ Teste outro navegador\n\nüéØ Alternativa: Use APIs pagas (Whisper/AssemblyAI)'
            break
          case 'network':
            errorMessage = 'üåê Erro de rede!\n\nüí° Web Speech precisa de conex√£o.\n\nüéØ Alternativa: OpenAI Whisper funciona offline ap√≥s upload'
            break
          case 'service-not-allowed':
            errorMessage = 'Servi√ßo n√£o permitido'
            break
          default:
            errorMessage = `Erro Web Speech: ${event.error}`
        }
        
        reject(new Error(errorMessage))
      }

      recognition.onend = () => {
        onProgress('‚úÖ Web Speech API conclu√≠da!')
        resolve({
          words,
          text: finalTranscript.trim(),
          confidence: 0.8,
          language: 'pt-BR',
          duration: words.length > 0 ? Math.max(...words.map(w => w.end)) : 0,
          speakers: [...new Set(words.map(w => w.speaker).filter((s): s is string => Boolean(s)))],
          continuousCaptions: createContinuousCaptions(words),
          segments: []
        })
      }

      // Iniciar reconhecimento direto do microfone
      recognition.start()
      
      // Auto-parar ap√≥s 30 segundos
      setTimeout(() => {
        recognition.stop()
      }, 30000)
    })
  }

  // ‚ûï M√âTODO PRINCIPAL com FALLBACK INTELIGENTE - FASE 3
  async transcribe(
    videoFile: File,
    onProgress: (status: string) => void,
    provider: 'whisper' | 'assemblyai' | 'webspeech' = 'whisper', // ‚ûï NOVO: Whisper como padr√£o
    useWebSpeechFallback: boolean = true
  ): Promise<TranscriptionResult> {
    console.log('üöÄ TRANSCRIBE: Iniciando processo principal')
    console.log('üìÅ TRANSCRIBE: Arquivo:', videoFile.name, videoFile.size)
    console.log('üîß TRANSCRIBE: Provider:', provider)
    console.log('üîÑ TRANSCRIBE: Fallback ativo:', useWebSpeechFallback)
    console.log('üîë TRANSCRIBE: Keys dispon√≠veis:', {
      openai: !!this.openaiApiKey,
      assemblyai: !!this.apiKey
    })

    // ‚úÖ FASE 1: VERIFICAR CACHE INTELIGENTE
    onProgress('üîç Verificando cache inteligente...')
    console.log('üíæ CACHE: Verificando se transcri√ß√£o j√° existe...')
    
    try {
      const cachedResult = await transcriptionCache.checkCache(videoFile, provider)
      if (cachedResult) {
        console.log('‚úÖ CACHE HIT: Transcri√ß√£o encontrada no cache!')
        console.log('üí∞ ECONOMIA: Evitando nova transcri√ß√£o, economizando custos')
        onProgress(`‚úÖ Cache hit! Carregando transcri√ß√£o salva (${provider})...`)
        
        // Simular um pequeno delay para UX
        await new Promise(resolve => setTimeout(resolve, 500))
        onProgress(`üéâ Transcri√ß√£o carregada do cache!`)
        
        // Garantir compatibilidade de tipos
        return {
          ...cachedResult.result,
          continuousCaptions: cachedResult.result.continuousCaptions || createContinuousCaptions(cachedResult.result.words),
          segments: cachedResult.result.segments || []
        }
      } else {
        console.log('‚ùå CACHE MISS: Transcri√ß√£o n√£o encontrada, processando...')
        onProgress(`üîÑ Processando nova transcri√ß√£o com ${provider}...`)
      }
    } catch (cacheError) {
      console.warn('‚ö†Ô∏è CACHE: Erro na verifica√ß√£o (n√£o cr√≠tico):', cacheError)
      onProgress('‚ö†Ô∏è Cache indispon√≠vel, processando normalmente...')
    }

    // ‚úÖ FASE 3: FALLBACK INTELIGENTE com Circuit Breaker
    try {
      console.log('üöÄ TRANSCRIBE: Usando sistema de fallback inteligente')
      onProgress('üß† Iniciando fallback inteligente...')

      // Configurar opera√ß√µes para cada provedor
      const operations = {
        openai: async () => {
          if (!this.openaiApiKey) {
            throw new Error('Configure OpenAI API Key para usar Whisper')
          }
          onProgress('üéØ OpenAI Whisper (Melhor qualidade)...')
          return await this.transcribeWithWhisper(videoFile, onProgress)
        },
        
        assemblyai: async () => {
          if (!this.apiKey || !this.assemblyAI) {
            throw new Error('Configure AssemblyAI API Key primeiro')
          }
          onProgress('ü§ñ AssemblyAI (R√°pido e confi√°vel)...')
          return await this.transcribeWithAssemblyAI(videoFile, onProgress)
        },
        
        webspeech: async () => {
          onProgress('üé§ Web Speech API (Gr√°tis, microfone)...')
          return await this.transcribeWithWebSpeech(videoFile, onProgress)
        }
      }

      // Executar com fallback inteligente
      const fallbackResult = await intelligentFallback.executeWithFallback(
        operations,
        provider === 'whisper' ? ['openai', 'assemblyai', 'webspeech'] :
        provider === 'assemblyai' ? ['assemblyai', 'openai', 'webspeech'] :
        ['webspeech', 'openai', 'assemblyai']
      )

      const result = fallbackResult.result as TranscriptionResult
      const usedProvider = fallbackResult.providerId
      const attempts = fallbackResult.attempts
      const fallbackUsed = fallbackResult.fallbackUsed

      console.log('‚úÖ TRANSCRIBE: Sucesso com fallback inteligente!')
      console.log('üìä TRANSCRIBE: Resultado:', {
        provider: usedProvider,
        attempts,
        fallbackUsed,
        words: result.words?.length || 0,
        text: result.text?.substring(0, 100) + '...',
        confidence: result.confidence,
        language: result.language
      })

      // Mostrar progresso do fallback
      if (fallbackUsed) {
        onProgress(`‚úÖ Sucesso com ${usedProvider} (${attempts} tentativas)`)
      } else {
        onProgress(`‚úÖ Sucesso direto com ${usedProvider}`)
      }
      
      // ‚úÖ SALVAR NO CACHE INTELIGENTE
      try {
        console.log('üíæ CACHE: Salvando transcri√ß√£o para futuras consultas...')
        onProgress('üíæ Salvando no cache inteligente...')
        
        // Calcular custo estimado baseado no provedor usado
        const estimatedCost = this.calculateTranscriptionCost(
          usedProvider === 'openai' ? 'whisper' : 
          usedProvider === 'assemblyai' ? 'assemblyai' : 'webspeech',
          videoFile.size, 
          result.duration || 0
        )
        
        await transcriptionCache.saveToCache(
          videoFile, 
          usedProvider === 'openai' ? 'whisper' : 
          usedProvider === 'assemblyai' ? 'assemblyai' : 'webspeech',
          result, 
          estimatedCost
        )
        console.log('‚úÖ CACHE: Transcri√ß√£o salva com sucesso!')
        console.log('üí∞ ECONOMIA: Pr√≥ximas consultas ser√£o instant√¢neas')
      } catch (cacheError) {
        console.warn('‚ö†Ô∏è CACHE: Erro ao salvar (n√£o cr√≠tico):', cacheError)
      }
      
      return result
      
    } catch (error) {
      console.error('‚ùå TRANSCRIBE: Falha completa do sistema de fallback:', error)
      
      // ‚ûÖ FALLBACK FINAL: Dados simulados
      console.log('üîÑ TRANSCRIBE: Gerando transcri√ß√£o de demonstra√ß√£o como √∫ltimo recurso...')
      onProgress('üîÑ Gerando transcri√ß√£o de demonstra√ß√£o...')
      const demoResult = this.generateDemoTranscription(videoFile)
      console.log('‚úÖ TRANSCRIBE: Demo gerada:', demoResult)
      return demoResult
    }
  }

  // ‚ûï NOVO: M√©todo para gerar transcri√ß√£o de demonstra√ß√£o
  private generateDemoTranscription(videoFile: File): TranscriptionResult {
    const demoWords: TranscriptionWord[] = [
      { text: 'Ol√°', start: 0, end: 0.5, confidence: 0.95, highlight: false },
      { text: 'pessoal,', start: 0.5, end: 1.2, confidence: 0.92, highlight: false },
      { text: 'bem-vindos', start: 1.2, end: 2.0, confidence: 0.98, highlight: true },
      { text: 'ao', start: 2.0, end: 2.2, confidence: 0.95, highlight: false },
      { text: 'ClipsForge!', start: 2.2, end: 3.0, confidence: 0.99, highlight: true },
      { text: 'Hoje', start: 3.5, end: 4.0, confidence: 0.94, highlight: false },
      { text: 'vamos', start: 4.0, end: 4.5, confidence: 0.96, highlight: false },
      { text: 'criar', start: 4.5, end: 5.0, confidence: 0.93, highlight: false },
      { text: 'conte√∫do', start: 5.0, end: 5.8, confidence: 0.97, highlight: true },
      { text: 'incr√≠vel', start: 5.8, end: 6.5, confidence: 0.99, highlight: true },
      { text: 'para', start: 6.5, end: 6.8, confidence: 0.95, highlight: false },
      { text: 'redes', start: 6.8, end: 7.3, confidence: 0.94, highlight: false },
      { text: 'sociais.', start: 7.3, end: 8.0, confidence: 0.96, highlight: false },
      { text: 'Vamos', start: 8.5, end: 9.0, confidence: 0.95, highlight: false },
      { text: 'come√ßar?', start: 9.0, end: 9.8, confidence: 0.98, highlight: true }
    ]

    return {
      words: demoWords,
      text: demoWords.map(w => w.text).join(' '),
      confidence: 0.95,
      language: 'pt-BR',
      duration: 10,
      speakers: ['Demonstra√ß√£o'],
      continuousCaptions: [],
      segments: []
    }
  }

  // ‚ûï M√âTODO para verificar disponibilidade dos provedores
  getAvailableProviders(): { id: string, name: string, description: string, available: boolean, cost: string }[] {
    return [
      {
        id: 'whisper',
        name: 'üéØ OpenAI Whisper',
        description: 'Melhor qualidade, m√∫ltiplos idiomas, timestamps precisos',
        available: !!this.openaiApiKey,
        cost: '$0.006/min'
      },
      {
        id: 'assemblyai',
        name: 'ü§ñ AssemblyAI',
        description: 'R√°pido, confi√°vel, boa para podcasts longos',
        available: !!this.apiKey && !!this.assemblyAI,
        cost: '$0.37/hr'
      },
      {
        id: 'webspeech',
        name: 'üé§ Web Speech',
        description: 'Gr√°tis, funciona s√≥ com microfone (n√£o com arquivo)',
        available: this.isSecureContext() && (('webkitSpeechRecognition' in window) || ('SpeechRecognition' in window)),
        cost: 'Gr√°tis'
      }
    ]
  }

  // ‚ûï M√âTODO para configurar todas as API keys de uma vez
  configureAllKeys(keys: { openai?: string, assemblyai?: string }) {
    if (keys.openai) {
      this.setOpenAIApiKey(keys.openai)
    }
    if (keys.assemblyai) {
      this.setApiKey(keys.assemblyai)
    }
  }

  // ‚ûï NOVO: M√©todo para configurar rate limits espec√≠ficos por provedor
  configureRateLimits(limits: { 
    openai?: { rpm: number, tpm: number }, 
    assemblyai?: { rpm: number, tpm: number } 
  }) {
    console.log('üîß Configurando rate limits conservadores:', limits)
    
    // Salvar configura√ß√µes para uso futuro se necess√°rio
    if (limits.openai) {
      localStorage.setItem('openai_rate_limits', JSON.stringify(limits.openai))
    }
    if (limits.assemblyai) {
      localStorage.setItem('assemblyai_rate_limits', JSON.stringify(limits.assemblyai))
    }
  }

  // ‚ûï NOVO: Calcular custo estimado da transcri√ß√£o
  private calculateTranscriptionCost(provider: string, fileSize: number, duration: number): number {
    // Estimativas conservadoras baseadas nos pre√ßos oficiais
    switch (provider) {
      case 'whisper':
        // OpenAI Whisper: $0.006 por minuto
        return Math.round((duration / 60) * 0.006 * 100) / 100
      case 'assemblyai':
        // AssemblyAI: $0.37 por hora
        return Math.round((duration / 3600) * 0.37 * 100) / 100
      case 'webspeech':
        return 0 // Gr√°tis
      default:
        return 0
    }
  }

  // ‚ûï NOVO: Obter estat√≠sticas do cache
  async getCacheStats() {
    try {
      return await transcriptionCache.getStats()
    } catch (error) {
      console.error('‚ùå Erro ao obter estat√≠sticas do cache:', error)
      return {
        totalCached: 0,
        totalHits: 0,
        totalMisses: 0,
        costSaved: 0,
        providers: {},
        hitRate: 0
      }
    }
  }

  // ‚ûï NOVO: Limpar cache
  async clearCache() {
    try {
      await transcriptionCache.clearCache()
      console.log('üßπ Cache limpo com sucesso')
      return true
    } catch (error) {
      console.error('‚ùå Erro ao limpar cache:', error)
      return false
    }
  }
}

// ‚úÖ FUN√á√ÉO PARA CRIAR LEGENDAS CONT√çNUAS BONITAS
function createContinuousCaptions(words: TranscriptionWord[]): Array<{
  text: string
  start: number
  end: number
  confidence: number
}> {
  if (!words.length) return []
  
  const captions = []
  const wordsPerCaption = 5 // 5 palavras por legenda = legibilidade ideal
  
  for (let i = 0; i < words.length; i += wordsPerCaption) {
    const captionWords = words.slice(i, i + wordsPerCaption)
    const text = captionWords.map(w => w.text).join(' ')
    const start = captionWords[0].start
    const end = captionWords[captionWords.length - 1].end
    const confidence = captionWords.reduce((sum, w) => sum + (w.confidence || 0.9), 0) / captionWords.length
    
    captions.push({
      text,
      start,
      end,
      confidence
    })
  }
  
  console.log('üé¨ Legendas cont√≠nuas criadas:', captions.length, 'frases')
  return captions
}

// ‚úÖ INTERFACE PARA LEGENDAS CONT√çNUAS
interface ContinuousCaption {
  text: string
  start: number
  end: number
  confidence: number
}

export const transcriptionService = new TranscriptionService() 